{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 315Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 1.11Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 812Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [02:30, 3.30Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 511Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 1.33Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 1.53Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "gpt2.download_gpt2(model_name=\"124M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 03:41:42.290393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-29 03:41:42.291010: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m   sess \u001b[39m=\u001b[39m gpt2\u001b[39m.\u001b[39mreset_session(sess)\n\u001b[0;32m----> 5\u001b[0m gpt2\u001b[39m.\u001b[39;49mfinetune(sess,\n\u001b[1;32m      6\u001b[0m               dataset\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcnn.txt\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m               model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m124M\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m               steps\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m               run_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrun1\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m               learning_rate \u001b[39m=\u001b[39;49m \u001b[39m1e-5\u001b[39;49m\n\u001b[1;32m     11\u001b[0m               )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_2_simple/gpt_2.py:198\u001b[0m, in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mif\u001b[39;00m multi_gpu:\n\u001b[1;32m    196\u001b[0m     gpus \u001b[39m=\u001b[39m get_available_gpus()\n\u001b[0;32m--> 198\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mmodel(hparams\u001b[39m=\u001b[39;49mhparams, X\u001b[39m=\u001b[39;49mcontext, gpus\u001b[39m=\u001b[39;49mgpus, reuse\u001b[39m=\u001b[39;49mreuse)\n\u001b[1;32m    199\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(\n\u001b[1;32m    200\u001b[0m     input_tensor\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msparse_softmax_cross_entropy_with_logits(\n\u001b[1;32m    201\u001b[0m         labels\u001b[39m=\u001b[39mcontext[:, \u001b[39m1\u001b[39m:], logits\u001b[39m=\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m'\u001b[39m][:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m    203\u001b[0m tf_sample \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39msample_sequence(\n\u001b[1;32m    204\u001b[0m     hparams\u001b[39m=\u001b[39mhparams,\n\u001b[1;32m    205\u001b[0m     length\u001b[39m=\u001b[39msample_length,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[1;32m    209\u001b[0m     top_k\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gpt_2_simple/src/model.py:188\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    185\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m    186\u001b[0m batch, sequence \u001b[39m=\u001b[39m shape_list(X)\n\u001b[0;32m--> 188\u001b[0m wpe \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mget_variable(\u001b[39m'\u001b[39;49m\u001b[39mwpe\u001b[39;49m\u001b[39m'\u001b[39;49m, [hparams\u001b[39m.\u001b[39;49mn_ctx, hparams\u001b[39m.\u001b[39;49mn_embd],\n\u001b[1;32m    189\u001b[0m                      initializer\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mrandom_normal_initializer(stddev\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m))\n\u001b[1;32m    190\u001b[0m wte \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mget_variable(\u001b[39m'\u001b[39m\u001b[39mwte\u001b[39m\u001b[39m'\u001b[39m, [hparams\u001b[39m.\u001b[39mn_vocab, hparams\u001b[39m.\u001b[39mn_embd],\n\u001b[1;32m    191\u001b[0m                      initializer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mrandom_normal_initializer(stddev\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m))\n\u001b[1;32m    192\u001b[0m past_length \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m past \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m tf\u001b[39m.\u001b[39mshape(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mpast)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py:1617\u001b[0m, in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1601\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mget_variable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1602\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_variable\u001b[39m(name,\n\u001b[1;32m   1603\u001b[0m                  shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1615\u001b[0m                  synchronization\u001b[39m=\u001b[39mVariableSynchronization\u001b[39m.\u001b[39mAUTO,\n\u001b[1;32m   1616\u001b[0m                  aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE):\n\u001b[0;32m-> 1617\u001b[0m   \u001b[39mreturn\u001b[39;00m get_variable_scope()\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1618\u001b[0m       _get_default_variable_store(),\n\u001b[1;32m   1619\u001b[0m       name,\n\u001b[1;32m   1620\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1621\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1622\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1623\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1624\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1625\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1626\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1627\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1628\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1629\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1630\u001b[0m       custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1631\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1632\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1633\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py:1327\u001b[0m, in \u001b[0;36mVariableScope.get_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1325\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1326\u001b[0m   dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype\n\u001b[0;32m-> 1327\u001b[0m \u001b[39mreturn\u001b[39;00m var_store\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1328\u001b[0m     full_name,\n\u001b[1;32m   1329\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1330\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1331\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1332\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1333\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m   1334\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1335\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1336\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1337\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1338\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1339\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1340\u001b[0m     custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1341\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1342\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1343\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py:583\u001b[0m, in \u001b[0;36m_VariableStore.get_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    581\u001b[0m   \u001b[39mreturn\u001b[39;00m custom_getter(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcustom_getter_kwargs)\n\u001b[1;32m    582\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m   \u001b[39mreturn\u001b[39;00m _true_getter(\n\u001b[1;32m    584\u001b[0m       name,\n\u001b[1;32m    585\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    586\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    587\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    588\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    589\u001b[0m       reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    590\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    591\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    592\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    593\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    594\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    595\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    596\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    597\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    598\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py:536\u001b[0m, in \u001b[0;36m_VariableStore.get_variable.<locals>._true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vars:\n\u001b[1;32m    531\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mNo partitioner was provided, but a partitioned version of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mvariable was found: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0. Perhaps a variable of the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname was already created with partitioning?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[0;32m--> 536\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_variable(\n\u001b[1;32m    537\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    538\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    539\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    540\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    541\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    542\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    543\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    544\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    545\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    546\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    547\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    548\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    549\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    550\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/variable_scope.py:892\u001b[0m, in \u001b[0;36m_VariableStore._get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39m# ResourceVariables don't have an op associated with so no traceback\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(var, resource_variable_ops\u001b[39m.\u001b[39mResourceVariable):\n\u001b[0;32m--> 892\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m    893\u001b[0m tb \u001b[39m=\u001b[39m var\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mtraceback[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    894\u001b[0m \u001b[39m# Throw away internal tf entries and only take a few lines. In some\u001b[39;00m\n\u001b[1;32m    895\u001b[0m \u001b[39m# cases the traceback can be longer (e.g. if someone uses factory\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[39m# functions to create variables) so we take more than needed in the\u001b[39;00m\n\u001b[1;32m    897\u001b[0m \u001b[39m# default case.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "if sess:\n",
    "  sess = gpt2.start_tf_sess()\n",
    "else:\n",
    "  sess = gpt2.reset_session(sess)\n",
    "gpt2.finetune(sess,\n",
    "              dataset='cnn.txt',\n",
    "              model_name='124M',\n",
    "              steps=20,\n",
    "              run_name='run1',\n",
    "              restore_from='fresh',\n",
    "              learning_rate = 1e-5\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
